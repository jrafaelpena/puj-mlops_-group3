# Proyecto 4 MLOps

### [ğŸ¥ Ver video en YouTube](https://youtu.be/CgQ7kvihTHg)

Este repositorio contiene todos los artefactos, configuraciones y manifiestos necesarios para construir, desplegar y operar un pipeline completo de Machine Learning orientado a MLOps. A continuaciÃ³n encontrarÃ¡s:

<br>

## DescripciÃ³n

El objetivo de este taller es desplegar un pipeline de MLOps que cubra todo el ciclo de vida de un modelo de Machine Learning, desde la ingesta de datos brutos hasta la entrega de resultados de inferencia a travÃ©s de una API y una interfaz web.

<br>

## Componentes principales

1. **Airflow**: Orquesta la recolecciÃ³n, preprocesamiento y entrenamiento continuo de un modelo.
2. **MLflow**: Registra experimentos, mÃ©tricas e historial de modelos.
3. **Bases de datos (PostgreSQL/MySQL)**: Almacenan datos RAW, datos limpios y metadatos para MLflow.
4. **MinIO**: Bucket que actÃºa como sistema de archivos para artefactos (modelos, reportes, logs).
5. **FastAPI (Inference API)**: Expone un endpoint REST para recibir solicitudes de inferencia usando el Ãºltimo modelo en producciÃ³n.
6. **Streamlit (UI de inferencia)**: Interfaz web que permite al usuario final interactuar con el modelo, visualizar resultados y explorar versiones histÃ³ricas.
7. **Prometheus & Grafana**: Capturan mÃ©tricas de latencia y trÃ¡fico de la API para anÃ¡lisis en tiempo real.
8. **Locust**: Herramienta de pruebas de carga para evaluar el rendimiento de la Inference API.
9. **Argo CD**: GitOps para mantener todos los manifiestos de Kubernetes sincronizados y facilitar despliegues declarativos.

Todo lo anterior se ejecuta sobre un clÃºster Kubernetes (MicroK8s, EKS, GKE, etc.) y se basa en manifiestos organizados en carpetas â€œbase/â€ y â€œoverlays/â€ para facilitar la reutilizaciÃ³n.

<br>

## Diagrama de arquitectura del proyect

<img src="images/project.jpg" width="95%">

<br>

## Estructura del repositorio

    â”œâ”€â”€ .argocd-apps/
    â”‚   â”œâ”€â”€ airflow-app.yaml
    â”‚   â”œâ”€â”€ inference-api-app.yaml
    â”‚   â”œâ”€â”€ streamlit-app.yaml
    â”‚   â””â”€â”€ apps-of-apps.yaml
    â”‚
    â”œâ”€â”€ apps/
    â”‚   â”œâ”€â”€ airflow/
    â”‚   â”‚   â”œâ”€â”€ dags/
    â”‚   â”‚   â”‚   â”œâ”€â”€ project-pipeline.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ raw_data_creation.sq
    â”‚   â”‚   â”‚   â””â”€â”€ utils.py
    â”‚   â”‚   â””â”€â”€ image/
    â”‚   â”‚       â”œâ”€â”€ Dockerfile
    â”‚   â”‚       â”œâ”€â”€ pyproject.toml
    â”‚   â”‚       â””â”€â”€ README.md
    â”‚   â”‚
    â”‚   â”œâ”€â”€ inference-api/
    â”‚   â”‚   â”œâ”€â”€ Dockerfile
    â”‚   â”‚   â”œâ”€â”€ pyproject.toml
    â”‚   â”‚   â”œâ”€â”€ .python-version
    â”‚   â”‚   â””â”€â”€ app/
    â”‚   â”‚       â””â”€â”€ main.py
    â”‚   â”‚
    â”‚   â”œâ”€â”€ streamlit/
    â”‚   â”‚   â”œâ”€â”€ Dockerfile
    â”‚   â”‚   â”œâ”€â”€ pyproject.toml
    â”‚   â”‚   â”œâ”€â”€ .python-version
    â”‚   â”‚   â””â”€â”€ streamlit_app.py
    â”‚   â”‚
    â”‚   â””â”€â”€ locust/
    â”‚       â””â”€â”€ locustfile.py
    â”‚
    â”œâ”€â”€ charts/
    â”‚   â””â”€â”€ airflow/
    â”‚       â””â”€â”€ Chart.yaml
    â”‚
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ arquitectura_proyecto.png
    â”‚   â”œâ”€â”€ dag_flow.png
    â”‚   â””â”€â”€ ...
    â”‚
    â”œâ”€â”€ k8s/
    â”‚   â”œâ”€â”€ base/
    â”‚   â”‚   â””â”€â”€ namespace.yaml
    â”‚   â”‚
    â”‚   â”œâ”€â”€ airflow/
    â”‚   â”‚   â””â”€â”€ values.yaml
    â”‚   â”‚
    â”‚   â”œâ”€â”€ inference-api/
    â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
    â”‚   â”‚   â””â”€â”€ inference-api.yaml
    â”‚   â”‚
    â”‚   â”œâ”€â”€ mlflow/
    â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
    â”‚   â”‚   â”œâ”€â”€ mysql.yaml
    â”‚   â”‚   â”œâ”€â”€ mysql-pvc.yaml
    â”‚   â”‚   â”œâ”€â”€ minio.yaml
    â”‚   â”‚   â”œâ”€â”€ minio-pv.yaml
    â”‚   â”‚   â””â”€â”€ mlflow.yaml
    â”‚   â”‚
    â”‚   â”œâ”€â”€ observability/
    â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
    â”‚   â”‚   â”œâ”€â”€ prometheus.yaml
    â”‚   â”‚   â”œâ”€â”€ grafana.yaml
    â”‚   â”‚   â””â”€â”€ grafana-dashboard-config.yam
    â”‚   â”‚
    â”‚   â”œâ”€â”€ postgres/
    â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
    â”‚   â”‚   â”œâ”€â”€ postgres.yaml
    â”‚   â”‚   â””â”€â”€ postgres-pvc.yaml
    â”‚   â”‚
    â”‚   â”œâ”€â”€ pvs/
    â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
    â”‚   â”‚   â”œâ”€â”€ minio-pv.yaml
    â”‚   â”‚   â”œâ”€â”€ mysql-pv.yaml
    â”‚   â”‚   â””â”€â”€ postgres-pv.yaml
    â”‚   â”‚
    â”‚   â””â”€â”€ streamlit/
    â”‚       â”œâ”€â”€ kustomization.yaml
    â”‚       â””â”€â”€ streamlit.yaml
    â”‚
    â”œâ”€â”€ .argocd-apps/
    â”‚   â”œâ”€â”€ airflow-app.yaml
    â”‚   â”œâ”€â”€ inference-api-app.yaml
    â”‚   â”œâ”€â”€ streamlit-app.yaml
    â”‚   â””â”€â”€ apps-of-apps.yaml
    â”‚
    â”œâ”€â”€ Makefile / deploy.sh
    â”œâ”€â”€ README.md
    â””â”€â”€ LICENSE

<br>

## Desarrollo

### 1. CreaciÃ³n automÃ¡tica del bucket Minio

Al desplegar MLflow en Kubernetes, necesitamos asegurarnos de que existan dos buckets en Minio para almacenar artefactos y datos relacionados:

- mlflows3
- api-artifacts

En lugar de crear manualmente estos buckets despuÃ©s de levantar Minio, se configuran _init containers_ dentro del Deployment de MLflow para:
- Esperar a que Minio estÃ© listo.
- Crear (si no existen) los buckets necesarios.

De esta forma, cada vez que MLflow se inicie (o se redeploye), se garantiza que los buckets estÃ©n presentes, evitando errores de artefactos faltantes en tiempo de ejecuciÃ³n.

<br>


### 2. Grafana

ConfigMaps usados para provisionar automÃ¡ticamente Grafana en Kubernetes: definir la fuente de datos (Prometheus), configurar el proveedor de dashboards (dashboard provider) y cargar el dashboard en sÃ­ (JSON).

**grafana-datasource**

- Este ConfigMap define la(s) fuente(s) de datos (datasource) que Grafana debe registrar al iniciar. En este caso, se le estÃ¡ indicando que agregue Prometheus como datasource por defecto, apuntando al servicio http://prometheus:9090. Grafana leerÃ¡ automÃ¡ticamente el contenido de datasource.yaml en /etc/grafana/provisioning/datasources/. Al levantar el pod de Grafana, encontrarÃ¡ el datasource â€œPrometheusâ€ configurado, sin necesidad de hacerlo manualmente vÃ­a UI. Gracias a la clave isDefault: true, cualquier panel nuevo utilizarÃ¡ a Prometheus como fuente de mÃ©tricas.


**grafana-dashboard-provider**

- Define la forma en que Grafana debe buscar archivos JSON de dashboards dentro del contenedor. Es el â€œdashboard providerâ€ que apunta a un directorio local (/var/lib/grafana/dashboards). Se crea un ConfigMap que Grafana montarÃ¡ en /etc/grafana/provisioning/dashboards/provider.yaml. Grafana escanearÃ¡ cada updateIntervalSeconds (10 s) la ruta /var/lib/grafana/dashboards en busca de archivos JSON. Al encontrar grafana-dashboard.json (u otros JSON), los cargarÃ¡ como dashboards â€œprovisionadosâ€ en la organizaciÃ³n (orgId = 1), sin permitir su eliminaciÃ³n desde la interfaz (disableDeletion: false significa que sÃ­ se pueden eliminar, pero suelen llenarse/reescribirse desde este provider). allowUiUpdates: true permite editarlo desde la UI, aunque cualquier cambio local puede perderse en el prÃ³ximo reinicio si se sobrescribe el ConfigMap.

**rafana-dashboard-config**

- Contiene el JSON completo del dashboard que se desea provisionar en Grafana. El label grafana_dashboard: "1" hace que, al montar el ConfigMap en el directorio de dashboards, Grafana lo reconozca y lo cargue automÃ¡ticamente. Grafana monta este ConfigMap (por ejemplo, bajo /var/lib/grafana/dashboards/grafana-dashboard.json). Gracias al â€œdashboard providerâ€ configurado en grafana-dashboard-provider.yaml, Grafana detecta este archivo JSON y lo importa como un dashboard nuevo llamado â€œTablero Proyecto 4â€. Este JSON define: Paneles, fuentes de datos, mÃ©tricas, expresiones PromQL (por ejemplo, rate(http_requests_total[5m])), disposiciÃ³n (gridPos), opciones de estilo (dark), intervalos de refresco (10 s), etc. Cada vez que se actualice este ConfigMap a nivel de Kubernetes, Grafana sobrescribirÃ¡ el dashboard con la nueva versiÃ³n del JSON.
<br>


### 3. Dag

Este DAG estÃ¡ diseÃ±ado para operar de manera completamente automÃ¡tica. Se encarga de procesar por lotes (batch) los datos de precios de casas, realizando tareas de carga, limpieza, entrenamiento y evaluaciÃ³n de modelos.

El pipeline incluye dos mecanismos clave:

    AirflowSkipException
    
En la primera tarea (evaluate_run_and_load_raw_data), si la API de datos indica que no hay mÃ¡s lotes disponibles (o retorna un error HTTP), se lanza esta excepciÃ³n. Esto detiene el DAG sin marcarlo como fallido, evitando asÃ­ ejecuciones innecesarias y previendo loops infinitos.

    TriggerDagRunOperator
    
Cuando todas las tareas se ejecutan correctamente, esta operaciÃ³n dispara automÃ¡ticamente una nueva ejecuciÃ³n del mismo DAG para procesar el siguiente lote. AsÃ­ se logra una secuencia encadenada de ejecuciones sin intervenciÃ³n manual.

Este mecanismo permite que el pipeline:
- Se reinicie automÃ¡ticamente cuando se procesÃ³ un lote exitosamente.
- Se detenga de forma segura cuando ya no hay mÃ¡s datos por procesar.

El pipeline es completamente autÃ³nomo, procesando cada lote de datos de forma escalonada hasta agotar la fuente sin necesidad de loops explÃ­citos.

<br>


### 4. Pipeline

El flujo de entrenamiento estÃ¡ diseÃ±ado con una lÃ³gica robusta de control de versiones de modelos y comparaciÃ³n de desempeÃ±o utilizando MLflow.

**Funciones principales**

    evaluate_run_and_load_raw_data:
Obtiene el lote desde una API externa y lo almacena en la base de datos.

    preprocess_and_split:
Limpia los datos, crea bins de precios para estratificaciÃ³n y separa en conjuntos de entrenamiento y prueba.

    train_decesision:
EvalÃºa si el tamaÃ±o del nuevo lote justifica reentrenar el modelo (se entrena si el 60% o mÃ¡s de los datos son nuevos).

    train_model:
Entrena el modelo con LinearRegression y OneHotEncoder, evalÃºa el desempeÃ±o con custom_reports_regression y lo registra en MLflow.

**LÃ³gica de "Champion" y "Challenger"**

El pipeline implementa una lÃ³gica de control de versiones y evaluaciÃ³n progresiva:

- El primer modelo (lote 0) se registra automÃ¡ticamente como champion.

- Los modelos entrenados en lotes posteriores se registran como challenger.

- Se comparan las mÃ©tricas de evaluaciÃ³n, especialmente el RMSE.

- Si el modelo challenger tiene mejor o igual RMSE que el actual champion, entonces:

- Se actualiza el alias champion en MLflow.

- Se llama a la API de inferencia para cargar el nuevo modelo.

Esta arquitectura permite que solo los mejores modelos pasen a producciÃ³n, garantizando mejoras continuas en el sistema sin necesidad de supervisiÃ³n manual.


<br>


### 5. Github Actions

**Workflows**

*1. project-4.yaml*
   
AutomÃ¡ticamente reconstruye y publica imÃ¡genes Docker para los componentes inference-api y streamlit del proyecto proyecto-4.

- Se ejecuta manualmente desde GitHub (workflow_dispatch).
- Clona el cÃ³digo del repo

- Hace login a Docker Hub usando secretos

- Publica las imÃ¡genes en Docker Hub

- Construye dos imÃ¡genes con docker buildx:

        jrpenagu/fastapi-house-prices

        jrpenagu/streamlit-house-prices

- Etiqueta las imÃ¡genes con:

        :latest

        El SHA corto del commit (ej. :e4a1c9)

<br>

Este workflow se activa cuando se hace push a la rama main y hay cambios en:

- apps/inference-api/**

- apps/streamlit/**


<br>


*2. ci-cd.yml*
   
Ejecuta un flujo CI mÃ¡s especializado para la API de inferencia (fast-api-iris) de un taller, incluyendo instalaciÃ³n de dependencias, entrenamiento y publicaciÃ³n de modelo.

- Se ejecuta con push a main en:

    4/taller-ci-cd/api-inferencia/**

    4/taller-ci-cd/params.yaml
    TambiÃ©n admite ejecuciÃ³n manual.

- Clona el cÃ³digo

- Instala dependencias con uv (gestor de entornos)

- Configura Python segÃºn .python-version

- Entrena un modelo ejecutando train_model.py

- Publica el modelo entrenado como artefacto de GitHub Actions
- A diferencia del primer workflow, este no construye imÃ¡genes Docker, sino que automatiza el flujo de ML con instalaciÃ³n, entrenamiento y almacenamiento del modelo.


El flujo principal (project-4.yaml) garantiza que los contenedores de producciÃ³n siempre estÃ©n actualizados cuando se modifican sus scripts o dependencias. Por su parte, el segundo workflow (ci-cd.yml) permite gestionar el ciclo de vida del modelo de ML, facilitando el entrenamiento reproducible y la publicaciÃ³n.

<br>

## Conclusiones

Este taller ofrece una guÃ­a completa y prÃ¡ctica para desplegar un pipeline de MLOps moderno, completamente automatizado, modular y desplegable en Kubernetes. A lo largo del desarrollo, se integran mÃºltiples tecnologÃ­as que permiten cubrir todo el ciclo de vida de un modelo de machine learning:
- OrquestaciÃ³n de procesamiento y entrenamiento por lotes con Airflow, incluyendo mecanismos automÃ¡ticos de parada (AirflowSkipException) y reinicio (TriggerDagRunOperator), garantizando un flujo autÃ³nomo sin loops infinitos.
- Registro de experimentos y control de versiones con MLflow, respaldado por almacenamiento en MinIO y metadatos en MySQL, lo cual permite comparar mÃ©tricas y realizar despliegue controlado mediante el esquema champion/challenger.
- Despliegue de modelos mediante un servicio de inferencia REST (FastAPI), con recarga automÃ¡tica del modelo cuando un nuevo challenger supera al champion.
- VisualizaciÃ³n de resultados y mÃ©tricas con Streamlit, ofreciendo una interfaz ligera e interactiva para explorar los datos y predicciones.
- Monitoreo de mÃ©tricas en tiempo real con Prometheus y Grafana, incluyendo dashboards provisionados automÃ¡ticamente desde Kubernetes mediante ConfigMaps.
- AutomatizaciÃ³n del entrenamiento y despliegue con GitHub Actions, a travÃ©s de dos workflows:

    - project-4.yaml: detecta cambios en los scripts y dependencias de inference-api y streamlit, construye las imÃ¡genes Docker, las etiqueta y publica automÃ¡ticamente en Docker Hub.

    - ci-cd.yml: gestiona el ciclo de vida del modelo ML para una API de inferencia, ejecutando instalaciÃ³n, entrenamiento y publicaciÃ³n del modelo como artefacto.
      
- Infraestructura definida como cÃ³digo mediante manifiestos YAML y Kustomize, desplegada y sincronizada con Argo CD, asegurando consistencia entre versiones y facilidad de rollback o actualizaciÃ³n.
