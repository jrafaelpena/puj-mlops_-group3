# Proyecto 3: Kubernetes, Prometheus y Grafana

### [ðŸŽ¥ Ver video en YouTube](https://youtu.be/SKmrt0lwFZg)


## Arquitecura del proyecto

<img src="images/arquitectura_proyecto.png" width="95%">

Como se puede observar en la imagen superior, se utilizaron dos mÃ¡quinas virtuales. Una de ellas se destinÃ³ exclusivamente al despliegue de los servicios relacionados con Apache Airflow, exponiendo Ãºnicamente el *webserver*. Para este propÃ³sito se utilizÃ³ **Docker Compose**.

En la otra mÃ¡quina virtual, que aloja la mayorÃ­a de los servicios restantes, se empleÃ³ **MicroK8s** como orquestador, desplegando todos los componentes dentro de un mismo *namespace* de **Kubernetes**.

## Estructura del repositorio

Se creÃ³ una carpeta para cada uno de los servicios, donde se almacenan los archivos correspondientes a los recursos de tipo *Deployment*, *Service* y *PersistentVolumeClaim* (PVC), cuando son requeridos. AdemÃ¡s, se creÃ³ una carpeta separada para los archivos relacionados con los recursos de tipo *PersistentVolume* (PV), ya que estos no estÃ¡n ligados a un *Pod* especÃ­fico y pueden ser reclamados por cualquier *claim*. Las carpetas `hostPath` asociadas a los PV se encuentran fuera del repositorio.

```md
proyecto-3
â”œâ”€â”€ airflow
â”œâ”€â”€ grafana
â”œâ”€â”€ images
â”œâ”€â”€ inference-api
â”œâ”€â”€ locust
â”œâ”€â”€ minio
â”œâ”€â”€ mlflow
â”œâ”€â”€ mysql
â”œâ”€â”€ observability
â”œâ”€â”€ postgres
â”œâ”€â”€ project-namespace.yaml
â”œâ”€â”€ prometheus
â”œâ”€â”€ pvs
â”œâ”€â”€ README.md
â””â”€â”€ streamlit
```

## Paso 1. Aseguramiento de imÃ¡genes

Dado que Kubernetes se encarga de orquestar contenedores pero no de construir imÃ¡genes, es necesario garantizar que todas las imÃ¡genes personalizadas estÃ©n disponibles en un repositorio como **Docker Hub**. En este proyecto, algunos servicios utilizan imÃ¡genes estÃ¡ndar proporcionadas por las tecnologÃ­as correspondientes, mientras que otros requieren imÃ¡genes personalizadas, ya sea reutilizadas de un proyecto anterior o creadas especÃ­ficamente para este entorno. En estos casos, las imÃ¡genes personalizadas deben subirse previamente al repositorio de Docker Hub.

Un ejemplo claro de esta necesidad es el caso de la segunda mÃ¡quina virtual, que debe utilizar una imagen personalizada de **Airflow** con las librerÃ­as necesarias para el entrenamiento. Para ello, se utilizan los siguientes comandos:

```bash
docker tag airflow-uv:latest jrpenagu/airflow-uv-ml:latest
docker push jrpenagu/airflow-uv-ml:latest 
```
Para los servicios de `inference-api`, `locust` y `streamlit`, se construyeron primero las imÃ¡genes, ya que dependen de nuevos desarrollos ajustados a los datos actualizados del caso de diabetes y a nuevos requerimientos especÃ­ficos.

## Paso 2. CreaciÃ³n de *namespace* para proyecto

Con el fin de tener un entorno aislado para todos los despliegues del proyecto y garantizar que estos se encuentren en una misma red, donde puedan comunicarse entre sÃ­ utilizando Ãºnicamente sus nombres de servicio, se creÃ³ el *namespace* `project-3-mlops` con el siguiente manifiesto en YAML:

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: project-3-mlops
```

## Paso 3. CreaciÃ³n de PVs

Se crean todos los PVs que posteriormente serÃ¡n reclamados por los *PersistentVolumeClaims* (PVCs) definidos en los despliegues. En total, se crean tres PVs, correspondientes a los servicios de `postgres`, `minio` y `mysql`:

<img src="images/pvs.png" width="90%">

## Paso 4. Carga de datos y entrenamiento de modelo

Una vez desplegados los servicios de `postgres` y `mlflow` (incluyendo sus servicios dependientes), se procede con la carga de datos y el entrenamiento del modelo a travÃ©s de **Airflow**. Para ello, se crea el **DAG** `1-diabetes-training-pipeline`, que sigue el siguiente flujo:

<img src="images/dag_flow.png" width="60%">

En la tarea de `1-diabetes-training-pipeline`


## Paso 5. ElecciÃ³n de modelo en mlflow

## Paso 6. Despliegue API en docs e insercion en sql

## Paso 7. Streamlit

## Paso 8. Locust, Grafana, y Prometheus






